{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "r = RandomForestClassifier() \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = KNeighborsClassifier()\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "g = GaussianNB()\n",
    "\n",
    "b = BernoulliNB()\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score , mean_squared_error , mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_last.csv\")\n",
    "\n",
    "# Asıl titanic ödevindeki dummye kadar olan kısmı indirdim ve burada kullanıyoruö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"ttrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"ttest.csv\")\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch Embarked Title  FamilySize\n",
       "0       0.0       3    male  22.0      1      0        S    Mr           2\n",
       "1       1.0       1  female  38.0      1      0        C   Mrs           2\n",
       "2       1.0       3  female  26.0      0      0        S  Miss           1\n",
       "3       1.0       1  female  35.0      1      0        S   Mrs           2\n",
       "4       0.0       3    male  35.0      0      0        S    Mr           1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    891 non-null    float64\n",
      " 1   Pclass      1309 non-null   int64  \n",
      " 2   Sex         1309 non-null   object \n",
      " 3   Age         1309 non-null   float64\n",
      " 4   SibSp       1309 non-null   int64  \n",
      " 5   Parch       1309 non-null   int64  \n",
      " 6   Embarked    1309 non-null   object \n",
      " 7   Title       1309 non-null   object \n",
      " 8   FamilySize  1309 non-null   int64  \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 92.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      418\n",
       "Pclass          0\n",
       "Sex             0\n",
       "Age             0\n",
       "SibSp           0\n",
       "Parch           0\n",
       "Embarked        0\n",
       "Title           0\n",
       "FamilySize      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum = pd.get_dummies(df , drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 13)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_dum[:891]\n",
    "x_test = df_dum[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    891 non-null    float64\n",
      " 1   Pclass      891 non-null    int64  \n",
      " 2   Age         891 non-null    float64\n",
      " 3   SibSp       891 non-null    int64  \n",
      " 4   Parch       891 non-null    int64  \n",
      " 5   FamilySize  891 non-null    int64  \n",
      " 6   Sex_male    891 non-null    uint8  \n",
      " 7   Embarked_Q  891 non-null    uint8  \n",
      " 8   Embarked_S  891 non-null    uint8  \n",
      " 9   Title_Miss  891 non-null    uint8  \n",
      " 10  Title_Mr    891 non-null    uint8  \n",
      " 11  Title_Mrs   891 non-null    uint8  \n",
      " 12  Title_miss  891 non-null    uint8  \n",
      "dtypes: float64(2), int64(4), uint8(7)\n",
      "memory usage: 48.0 KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train[\"Survived\"]\n",
    "y_train=df1[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [g,b,k,log,gbc,r,d,xgbc]\n",
    "names = ['GaussianNB', 'BernoulliNB','K Nearest', 'Logistic', 'Gradient Boosting', 'RandomForest', 'Decision Tree',\"XGBC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def algo_test(x, y, algorithms = algorithms, names = names):\n",
    " \n",
    "    #fit the data\n",
    "    for i in range(len(algorithms)):\n",
    "        algorithms[i] = algorithms[i].fit(x, y)\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = [] \n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for i in range(len(algorithms)):\n",
    "\n",
    "        accuracy.append(accuracy_score(y, algorithms[i].predict(x))) \n",
    "        precision.append(precision_score (y, algorithms[i].predict(x))) \n",
    "        recall.append(recall_score (y, algorithms[i].predict(x)))\n",
    "        f1.append(f1_score (y, algorithms[i].predict(x))) \n",
    "        \n",
    "    metrics = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall',\"F1\"], index = names)\n",
    "    metrics['Accuracy'] = accuracy\n",
    "    metrics['Precision'] = precision\n",
    "    metrics['Recall'] = recall\n",
    "    metrics['F1'] = f1 \n",
    "    \n",
    "    return metrics.sort_values('F1', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oztur\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.937149</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.914634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.937149</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>0.865497</td>\n",
       "      <td>0.913580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBC</th>\n",
       "      <td>0.918070</td>\n",
       "      <td>0.949833</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.886115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.882155</td>\n",
       "      <td>0.893688</td>\n",
       "      <td>0.786550</td>\n",
       "      <td>0.836703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest</th>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.798137</td>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.774096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.715655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.735202</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.711916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Precision    Recall        F1\n",
       "RandomForest       0.937149   0.955414  0.877193  0.914634\n",
       "Decision Tree      0.937149   0.967320  0.865497  0.913580\n",
       "XGBC               0.918070   0.949833  0.830409  0.886115\n",
       "Gradient Boosting  0.882155   0.893688  0.786550  0.836703\n",
       "K Nearest          0.838384   0.811321  0.754386  0.781818\n",
       "Logistic           0.831650   0.798137  0.751462  0.774096\n",
       "GaussianNB         0.800224   0.788732  0.654971  0.715655\n",
       "BernoulliNB        0.785634   0.735202  0.690058  0.711916"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12 , activation  =\"relu\"))\n",
    "model.add(Dense(18 ,   activation  =\"relu\"))\n",
    "model.add(Dense(18 ,   activation  =\"relu\"))\n",
    "model.add(Dense(12 , activation  =\"relu\"))\n",
    "model.add(Dense(1 ,  activation  =\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\" , optimizer = \"adam\" , metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 [==============================] - 1s 852us/step - loss: 0.6500 - accuracy: 0.6117\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 852us/step - loss: 0.5990 - accuracy: 0.6678\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 874us/step - loss: 0.5538 - accuracy: 0.7441\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 874us/step - loss: 0.5078 - accuracy: 0.7632\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 852us/step - loss: 0.4885 - accuracy: 0.7957\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 874us/step - loss: 0.4768 - accuracy: 0.7901\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 885us/step - loss: 0.5064 - accuracy: 0.7767\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 863us/step - loss: 0.4689 - accuracy: 0.7957\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 0s 909us/step - loss: 0.4617 - accuracy: 0.8047\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 0s 840us/step - loss: 0.4535 - accuracy: 0.8047\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 0s 874us/step - loss: 0.4633 - accuracy: 0.8058\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 0s 863us/step - loss: 0.4515 - accuracy: 0.8103\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 0s 863us/step - loss: 0.4445 - accuracy: 0.8137\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 0s 852us/step - loss: 0.4399 - accuracy: 0.8193\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 0s 863us/step - loss: 0.4431 - accuracy: 0.8193\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 0s 874us/step - loss: 0.4561 - accuracy: 0.8204\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 0s 885us/step - loss: 0.4377 - accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 0s 874us/step - loss: 0.4341 - accuracy: 0.8193\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 0s 852us/step - loss: 0.4299 - accuracy: 0.8260\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 0s 863us/step - loss: 0.4266 - accuracy: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa8903b388>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs = 20 , batch_size = 10 , verbose = 1)\n",
    "\n",
    "# one hut encoding yapılması gerekcek araştır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 776us/step - loss: 0.4275 - accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_test[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 719us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oztur\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "c:\\Users\\oztur\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "result = df2[[\"PassengerId\"]]\n",
    "\n",
    "result[\"pred\"] = pred\n",
    "result[\"Survived\"] = result[\"pred\"].map(lambda x:1 if x>= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oztur\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "final_sol = df2[[\"PassengerId\"]]\n",
    "final_sol[\"Survived\"] = result[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sol.to_csv(\"final_titanic.csv\" , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16f3484daa4199d826ac59be93380ed5ae89d2875afe8f45f4b2e96f2f02b6fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
